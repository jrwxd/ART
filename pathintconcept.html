<!DOCTYPE html>
<html lang="en" class="scroll-smooth">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Interactive Explainer: Path Integral Latent Video Synthesis (Detailed)</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=Fira+Code:wght@400;500&display=swap" rel="stylesheet">
    
    <!-- Chosen Palette: Warm Stone & Indigo -->
    <!-- Application Structure Plan: Enhanced guided journey. Core concepts remain interactive. Framework tabs now include illustrative pseudocode snippets for key algorithms, revealed on interaction. Workflow modals also contain more technical detail and conceptual code. This deepens understanding by connecting abstract phases to concrete computational steps, maintaining usability via progressive disclosure of complexity. -->
    <!-- Visualization & Content Choices: 
        - Report Info: Path Parameterization (Sec 3.1) -> Goal: Show LERP code -> Viz/Method: Styled code block (HTML/CSS) within Phase 1 Tab -> Interaction: Static display, copy button -> Justification: Direct illustration of a core algorithm.
        - Report Info: Action Function Components (Sec 3.3) -> Goal: Connect sliders to formula and code -> Viz/Method: Display formula `Action = w_S * S_smooth - w_sem * S_sem`. Sliders update chart AND a conceptual code snippet showing `calculate_total_action` -> Interaction: Sliders drive multiple UI updates -> Justification: Makes the abstract formula and its parameters concrete and interactive.
        - Report Info: Path Integration (Sec 3.2, Phase 2) -> Goal: Explain weighting and averaging -> Viz/Method: Pseudocode for `get_path_weights` and `integrate_paths`. Simple canvas animation showing paths converging based on weights. -> Interaction: Code display, animation synced with explanation -> Justification: Visual and code-based explanation of a complex step.
        - Report Info: Workflow Modals (Sec 6) -> Goal: Add technical depth to each step -> Viz/Method: Modals now include a "Technical Snapshot" with key operations or pseudocode for that stage -> Interaction: Click node to open enhanced modal -> Justification: Layered information for users wanting more detail.
    -->
    <!-- CONFIRMATION: NO SVG graphics used. NO Mermaid JS used. -->

    <style>
        body {
            font-family: 'Inter', sans-serif;
            background-color: #F5F5F4; /* stone-100 */
            color: #292524; /* stone-800 */
        }
        .nav-link {
            transition: color 0.2s, transform 0.2s;
            display: inline-block;
        }
        .nav-link:hover {
            color: #4f46e5; /* indigo-600 */
            transform: translateY(-1px);
        }
        .concept-card {
            transition: transform 0.3s ease-out, box-shadow 0.3s ease-out, border-color 0.3s;
            border: 2px solid transparent;
        }
        .concept-card:hover, .concept-card.active-concept {
            transform: translateY(-6px) scale(1.02);
            box-shadow: 0 12px 20px -4px rgb(0 0 0 / 0.15), 0 5px 8px -5px rgb(0 0 0 / 0.1);
        }
        .concept-card.active-concept {
            border-color: #6366f1; /* indigo-500 */
        }
        .tab-button {
            transition: background-color 0.2s, color 0.2s, transform 0.2s;
        }
        .tab-button:hover:not(.active) {
            background-color: #e0e7ff; /* indigo-100 */
            color: #4338ca; /* indigo-700 */
            transform: translateY(-1px);
        }
        .tab-button.active {
            background-color: #4f46e5; /* indigo-600 */
            color: white;
            box-shadow: 0 4px 6px -1px rgb(0 0 0 / 0.1), 0 2px 4px -2px rgb(0 0 0 / 0.1);
        }
        .workflow-node {
            transition: all 0.3s ease-in-out;
            cursor: pointer;
        }
        .workflow-node:hover, .workflow-node.active-node {
            transform: scale(1.08) rotate(-1deg);
            background-color: #a78bfa; /* violet-400 */
            color: white;
            box-shadow: 0 8px 15px rgba(167, 139, 250, 0.3);
        }
        .workflow-arrow {
            position: relative;
            flex-grow: 1;
            height: 3px;
            background-color: #a5b4fc; /* indigo-300 */
            border-radius: 3px;
        }
        .workflow-arrow::after {
            content: '‚ñ∂'; 
            font-size: 16px;
            color: #a5b4fc;
            position: absolute;
            right: -10px; 
            top: 50%;
            transform: translateY(-50%);
        }
        .modal-overlay {
            transition: opacity 0.3s ease-in-out;
        }
        .modal-content {
            transition: transform 0.3s cubic-bezier(0.175, 0.885, 0.32, 1.275), opacity 0.3s ease-in-out;
        }
        .chart-container {
            position: relative;
            width: 100%;
            max-width: 600px;
            margin-left: auto;
            margin-right: auto;
            height: 350px;
            max-height: 400px;
            padding: 1rem;
            background-color: #f9fafb; /* gray-50 */
            border-radius: 0.5rem;
            box-shadow: inset 0 2px 4px 0 rgb(0 0 0 / 0.05);
        }
        @media (max-width: 768px) { .chart-container { height: 300px; } }
        
        input[type="range"] { -webkit-appearance: none; appearance: none; background: transparent; cursor: pointer; width: 100%; }
        input[type="range"]::-webkit-slider-runnable-track { background: #e5e7eb; height: 0.5rem; border-radius: 0.25rem; }
        input[type="range"]::-moz-range-track { background: #e5e7eb; height: 0.5rem; border-radius: 0.25rem; }
        input[type="range"]::-webkit-slider-thumb { -webkit-appearance: none; appearance: none; margin-top: -0.25rem; background-color: #4f46e5; height: 1rem; width: 1rem; border-radius: 9999px; border: 2px solid white; box-shadow: 0 1px 3px rgba(0,0,0,0.1); }
        input[type="range"]::-moz-range-thumb { background-color: #4f46e5; height: 1rem; width: 1rem; border-radius: 9999px; border: 2px solid white; box-shadow: 0 1px 3px rgba(0,0,0,0.1); }
        
        .challenge-future-card { transition: transform 0.2s ease-out, box-shadow 0.2s ease-out; }
        .challenge-future-card:hover { transform: translateY(-4px); box-shadow: 0 8px 16px -3px rgb(0 0 0 / 0.1), 0 3px 5px -3px rgb(0 0 0 / 0.1); }
        .section-icon { font-size: 1.5em; margin-right: 0.5rem; color: #818cf8; /* indigo-400 */ }

        .code-block {
            font-family: 'Fira Code', monospace;
            background-color: #282c34; /* Dark editor background */
            color: #abb2bf; /* Light text */
            padding: 1rem;
            border-radius: 0.5rem;
            font-size: 0.875em;
            line-height: 1.6;
            overflow-x: auto;
            margin-top: 0.75rem;
            margin-bottom: 0.75rem;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
            position: relative;
        }
        .code-block .keyword { color: #c678dd; } /* Purple for keywords */
        .code-block .function { color: #61afef; } /* Blue for functions */
        .code-block .comment { color: #5c6370; font-style: italic; } /* Gray for comments */
        .code-block .string { color: #98c379; } /* Green for strings */
        .code-block .number { color: #d19a66; } /* Orange for numbers */
        .code-block .variable { color: #e06c75; } /* Red for variables/parameters */
        .code-block .class { color: #e5c07b; } /* Yellow for class/type like names */
        .copy-code-btn {
            position: absolute;
            top: 0.5rem;
            right: 0.5rem;
            background-color: #4a5568;
            color: white;
            padding: 0.25rem 0.5rem;
            font-size: 0.75rem;
            border-radius: 0.25rem;
            cursor: pointer;
            transition: background-color 0.2s;
        }
        .copy-code-btn:hover { background-color: #2d3748; }
        .formula {
            font-family: 'Fira Code', monospace;
            background-color: #e0e7ff; /* indigo-100 */
            color: #3730a3; /* indigo-800 */
            padding: 0.75rem 1rem;
            border-radius: 0.375rem;
            text-align: center;
            font-size: 0.95em;
            margin: 1rem auto;
            display: inline-block;
            border: 1px solid #c7d2fe; /* indigo-200 */
        }
        .tooltip {
            position: relative;
            display: inline-block;
            cursor: help;
        }
        .tooltip .tooltiptext {
            visibility: hidden;
            width: 220px;
            background-color: #292524; /* stone-800 */
            color: #fff;
            text-align: center;
            border-radius: 6px;
            padding: 8px;
            position: absolute;
            z-index: 10;
            bottom: 125%;
            left: 50%;
            margin-left: -110px;
            opacity: 0;
            transition: opacity 0.3s;
            font-size: 0.8rem;
            line-height: 1.4;
        }
        .tooltip:hover .tooltiptext {
            visibility: visible;
            opacity: 1;
        }
    </style>
</head>
<body class="antialiased">

    <header class="bg-stone-50/90 backdrop-blur-md sticky top-0 z-50 border-b border-stone-200 shadow-sm">
        <nav class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8">
            <div class="flex items-center justify-between h-16">
                <div class="flex-shrink-0">
                    <h1 class="text-2xl font-bold text-indigo-600 flex items-center">
                        <span class="mr-2">üåå</span> Path Integral Synthesis
                    </h1>
                </div>
                <div class="hidden md:block">
                    <div class="ml-10 flex items-baseline space-x-1">
                        <a href="#vision" class="nav-link px-3 py-2 rounded-md text-sm font-medium text-stone-700 hover:text-indigo-600">‚ú® Vision</a>
                        <a href="#concepts" class="nav-link px-3 py-2 rounded-md text-sm font-medium text-stone-700 hover:text-indigo-600">üí° Core Concepts</a>
                        <a href="#framework" class="nav-link px-3 py-2 rounded-md text-sm font-medium text-stone-700 hover:text-indigo-600">üèóÔ∏è Framework</a>
                        <a href="#workflow" class="nav-link px-3 py-2 rounded-md text-sm font-medium text-stone-700 hover:text-indigo-600">üîÑ Interactive Workflow</a>
                        <a href="#challenges" class="nav-link px-3 py-2 rounded-md text-sm font-medium text-stone-700 hover:text-indigo-600">üéØ Challenges & Future</a>
                    </div>
                </div>
            </div>
        </nav>
    </header>

    <main class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-12">

        <section id="vision" class="text-center py-16 md:py-24">
             <h2 class="text-4xl font-bold tracking-tight text-stone-900 sm:text-5xl lg:text-6xl leading-tight">
                A <span class="text-indigo-600">New Spin</span> on Latent Diffusion
            </h2>
            <p class="mt-8 max-w-3xl mx-auto text-lg leading-8 text-stone-600">
                This interactive explainer unveils a novel framework for video generation: applying the principles of **path integrals** to the latent space of Stable Diffusion models. Journey beyond simple interpolation to explore a multitude of trajectories, aiming for richer, more dynamic, and semantically coherent video transitions.
            </p>
        </section>

        <section id="concepts" class="py-16">
            <div class="text-center mb-16">
                <h2 class="text-3xl font-bold tracking-tight text-stone-900 flex items-center justify-center"><span class="section-icon">üí°</span>Core Concepts Explained</h2>
                <p class="mt-4 max-w-2xl mx-auto text-lg text-stone-600">Click a card to delve into the foundational ideas and see a visual metaphor spring to life.</p>
            </div>
            <div class="grid md:grid-cols-3 gap-8">
                <div id="concept-card-1" class="concept-card bg-white p-6 rounded-xl shadow-lg cursor-pointer">
                    <h3 class="text-xl font-semibold mb-3 text-indigo-700 flex items-center"><span class="mr-2 text-2xl">üßä</span>1. Latent Space</h3>
                    <p class="text-stone-600 mb-4 text-sm">A compressed realm where complex data (like images) is elegantly represented. Actual Stable Diffusion latents are typically 4-channel tensors (e.g., `[1, 4, H/8, W/8]`). Smooth voyages here translate to fluid visual shifts.</p>
                    <canvas id="canvas-latent" class="w-full h-48 bg-stone-100 rounded-lg border border-stone-200"></canvas>
                </div>
                <div id="concept-card-2" class="concept-card bg-white p-6 rounded-xl shadow-lg cursor-pointer">
                    <h3 class="text-xl font-semibold mb-3 text-indigo-700 flex items-center"><span class="mr-2 text-2xl">üåø</span>2. Path Integral Adaptation</h3>
                    <p class="text-stone-600 mb-4 text-sm">Instead of one rigid path, we explore countless possibilities from start to end. Each "path" is a sequence of latent vectors, e.g., `[z_0, z_1, ..., z_N-1]`. The final video is a harmonious blend of these journeys, weighted by their "Action".</p>
                    <canvas id="canvas-path" class="w-full h-48 bg-stone-100 rounded-lg border border-stone-200"></canvas>
                </div>
                <div id="concept-card-3" class="concept-card bg-white p-6 rounded-xl shadow-lg cursor-pointer">
                    <h3 class="text-xl font-semibold mb-3 text-indigo-700 flex items-center"><span class="mr-2 text-2xl">üéûÔ∏è</span>3. Video Synthesis</h3>
                    <p class="text-stone-600 mb-4 text-sm">A video unfolds frame by frame. The essence (latent vector `Z_j`) for each frame is distilled from the "integrated" path, then decoded by the VAE. This generates a sequence of images forming a coherent visual narrative.</p>
                    <canvas id="canvas-video" class="w-full h-48 bg-stone-100 rounded-lg border border-stone-200"></canvas>
                </div>
            </div>
        </section>

        <section id="framework" class="py-16">
            <div class="text-center mb-16">
                <h2 class="text-3xl font-bold tracking-tight text-stone-900 flex items-center justify-center"><span class="section-icon">üèóÔ∏è</span>The 3-Phase Implementation Framework</h2>
                <p class="mt-4 max-w-2xl mx-auto text-lg text-stone-600">This structured approach deconstructs the complex task into clear, manageable phases. Explore each phase to see illustrative code and understand the core mechanics.</p>
            </div>
            <div class="mb-6 flex flex-col sm:flex-row justify-center space-y-2 sm:space-y-0 sm:space-x-2 p-1 bg-stone-200 rounded-lg shadow-inner">
                <button class="tab-button w-full sm:w-auto px-5 py-3 text-sm font-semibold rounded-md active" data-tab="phase1">Phase 1: Defining & Sampling</button>
                <button class="tab-button w-full sm:w-auto px-5 py-3 text-sm font-semibold rounded-md" data-tab="phase2">Phase 2: Integrating Paths</button>
                <button class="tab-button w-full sm:w-auto px-5 py-3 text-sm font-semibold rounded-md" data-tab="phase3">Phase 3: Control & Refinement</button>
            </div>
            <div class="bg-white p-8 md:p-10 rounded-xl shadow-xl">
                <!-- Phase 1 Content -->
                <div id="phase1" class="tab-content">
                    <h3 class="text-2xl font-semibold mb-3 text-stone-800">Phase 1: Defining and Sampling Paths</h3>
                    <p class="text-stone-600 mb-6 text-base leading-relaxed">This phase is about exploration: generating diverse trajectories (paths) in latent space. A path is a sequence of latent vectors, `[z_0, z_1, ..., z_N-1]`. We start with methods to create these paths.</p>
                    
                    <h4 class="font-semibold text-indigo-700 text-lg mt-6 mb-2">Path Parameterization: LERP Example</h4>
                    <p class="text-sm text-stone-600 mb-2">Linear Interpolation (LERP) is a basic way to create a path between a start (`z_start`) and end (`z_end`) latent vector.</p>
                    <div class="code-block">
                        <button class="copy-code-btn" onclick="copyCode(this)">Copy</button>
                        <pre><code class="language-python"><span class="keyword">def</span> <span class="function">linear_interpolation_path</span>(<span class="variable">z_start</span>, <span class="variable">z_end</span>, <span class="variable">num_frames</span>):
    <span class="comment"># Generates a path by linearly interpolating.</span>
    <span class="variable">latents</span> = []
    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="function">range</span>(<span class="variable">num_frames</span>):
        alpha = i / (<span class="variable">num_frames</span> - <span class="number">1</span>) <span class="keyword">if</span> <span class="variable">num_frames</span> > <span class="number">1</span> <span class="keyword">else</span> <span class="number">0.0</span>
        interpolated_latent = (<span class="number">1</span> - alpha) * <span class="variable">z_start</span> + alpha * <span class="variable">z_end</span>
        <span class="variable">latents</span>.append(interpolated_latent)
    <span class="keyword">return</span> torch.stack(<span class="variable">latents</span>)</code></pre>
                    </div>
                    <p class="text-sm text-stone-600 mt-2 mb-4">More advanced methods like <span class="tooltip">Splines<span class="tooltiptext">Splines (e.g., Catmull-Rom) create smoother paths by ensuring continuity of derivatives, leading to less jerky motion in the video.</span></span> can produce visually smoother transitions.</p>

                    <h4 class="font-semibold text-indigo-700 text-lg mt-6 mb-2">Path Generation: Perturbative Approach</h4>
                    <p class="text-sm text-stone-600 mb-2">We can create variations by adding noise to a baseline path (like LERP), keeping start/end points fixed.</p>
                     <div class="code-block">
                        <button class="copy-code-btn" onclick="copyCode(this)">Copy</button>
                        <pre><code class="language-python"><span class="keyword">def</span> <span class="function">perturb_path</span>(<span class="variable">base_path</span>, <span class="variable">noise_level</span>=<span class="number">0.1</span>):
    <span class="comment"># Adds random noise to intermediate frames of a base path.</span>
    <span class="variable">perturbed_path</span> = <span class="variable">base_path</span>.clone()
    <span class="keyword">if</span> <span class="variable">base_path</span>.shape[<span class="number">0</span>] > <span class="number">2</span>:
        noise = torch.randn_like(<span class="variable">base_path</span>[<span class="number">1</span>:-<span class="number">1</span>]) * <span class="variable">noise_level</span>
        <span class="variable">perturbed_path</span>[<span class="number">1</span>:-<span class="number">1</span>] += noise
    <span class="keyword">return</span> <span class="variable">perturbed_path</span></code></pre>
                    </div>

                    <h4 class="font-semibold text-indigo-700 text-lg mt-8 mb-2">The "Action" Function: Guiding Path Selection</h4>
                    <p class="text-sm text-stone-600 mb-1">Each path is scored by an "Action" function. A lower action value is generally "better". The formula is key:</p>
                    <div class="text-center my-3">
                        <p class="formula">Action = w<sub>smooth</sub> * S<sub>smooth</sub> - w<sub>semantic</sub> * S<sub>semantic</sub> + ...</p>
                    </div>
                    <p class="text-sm text-stone-600 mb-4">Here, `S_smooth` penalizes jerky paths (high "kinetic energy"), and `S_semantic` rewards paths aligning with textual prompts (e.g., via <span class="tooltip">CLIP scores<span class="tooltiptext">CLIP (Contrastive Language‚ÄìImage Pre-training) measures similarity between an image and a text description. Higher scores mean better alignment.</span></span>). The weights `w_smooth`, `w_semantic` allow creative control. Adjust them below!</p>
                    
                    <div class="mt-6">
                        <div class="chart-container">
                            <canvas id="actionChart"></canvas>
                        </div>
                        <div class="grid grid-cols-1 sm:grid-cols-2 gap-x-6 gap-y-4 mt-8 max-w-2xl mx-auto">
                            <div>
                                <label for="smoothness" class="block text-sm font-medium text-stone-700 mb-1">w<sub>smooth</sub> (Smoothness Weight)</label>
                                <input id="smoothness" type="range" min="0" max="100" value="70" class="w-full">
                            </div>
                            <div>
                                <label for="semantic" class="block text-sm font-medium text-stone-700 mb-1">w<sub>semantic</sub> (Semantic Weight)</label>
                                <input id="semantic" type="range" min="0" max="100" value="85" class="w-full">
                            </div>
                            <div>
                                <label for="constraint" class="block text-sm font-medium text-stone-700 mb-1">w<sub>constraint</sub> (Constraint Adherence)</label>
                                <input id="constraint" type="range" min="0" max="100" value="50" class="w-full">
                            </div>
                            <div>
                                <label for="novelty" class="block text-sm font-medium text-stone-700 mb-1">w<sub>novelty</sub> (Novelty/Exploration)</label>
                                <input id="novelty" type="range" min="0" max="100" value="40" class="w-full">
                            </div>
                        </div>
                        <p id="action-explainer" class="text-center mt-6 text-stone-600 text-sm max-w-xl mx-auto bg-indigo-50 p-3 rounded-md border border-indigo-200"></p>
                    </div>
                    <div id="action_code_container" class="mt-4">
                        <p class="text-sm text-stone-600 mb-2">Conceptual code for `calculate_total_action`:</p>
                        <div class="code-block">
                            <button class="copy-code-btn" onclick="copyCode(this)">Copy</button>
                            <pre><code id="action_code_snippet" class="language-python"><span class="keyword">def</span> <span class="function">calculate_total_action</span>(<span class="variable">path</span>, <span class="variable">w_smooth</span>, <span class="variable">w_semantic</span>, ...):
    <span class="variable">s_smooth</span> = <span class="function">calculate_smoothness_action</span>(<span class="variable">path</span>)
    <span class="variable">s_semantic</span> = <span class="function">calculate_semantic_action</span>(<span class="variable">path</span>, ...)
    
    <span class="comment"># Lower action is better</span>
    <span class="variable">total_action</span> = <span class="variable">w_smooth</span> * <span class="variable">s_smooth</span> - <span class="variable">w_semantic</span> * <span class="variable">s_semantic</span> 
    <span class="keyword">return</span> <span class="variable">total_action</span></code></pre>
                        </div>
                    </div>
                </div>
                <!-- Phase 2 Content -->
                <div id="phase2" class="tab-content hidden">
                    <h3 class="text-2xl font-semibold mb-3 text-stone-800">Phase 2: Integrating Over Paths</h3>
                    <p class="text-stone-600 mb-6 text-base leading-relaxed">After sampling many potential paths and calculating their "Action" scores, this phase combines their contributions to determine the final video trajectory. The core idea is a weighted average, where "better" paths (lower action) have more influence.</p>

                    <h4 class="font-semibold text-indigo-700 text-lg mt-6 mb-2">Path Weighting</h4>
                    <p class="text-sm text-stone-600 mb-2">The weight of each path is typically calculated as `exp(-Action / T)`, where `T` is a "temperature" parameter. Lower action or higher temperature gives higher weight.</p>
                    <div class="code-block">
                        <button class="copy-code-btn" onclick="copyCode(this)">Copy</button>
                        <pre><code class="language-python"><span class="keyword">def</span> <span class="function">get_path_weights</span>(<span class="variable">list_of_paths</span>, <span class="variable">temperature</span>=<span class="number">1.0</span>, ...):
    <span class="variable">actions</span> = [ <span class="function">calculate_total_action</span>(p, ...) <span class="keyword">for</span> p <span class="keyword">in</span> <span class="variable">list_of_paths</span> ]
    <span class="variable">actions_tensor</span> = torch.tensor(<span class="variable">actions</span>)
    
    <span class="comment"># Temperature T controls sensitivity to action differences</span>
    <span class="variable">weights</span> = torch.exp(-<span class="variable">actions_tensor</span> / <span class="variable">temperature</span>)
    
    <span class="keyword">return</span> <span class="variable">weights</span> / torch.sum(<span class="variable">weights</span>) <span class="comment"># Normalize</span></code></pre>
                    </div>

                    <h4 class="font-semibold text-indigo-700 text-lg mt-6 mb-2">Path Integration</h4>
                    <p class="text-sm text-stone-600 mb-2">The final latent vector `Z_j` for each frame `j` is the weighted average of the j-th latent vectors from all sampled paths: `Z_j = sum_k (weight_k * path_k_j) / sum_k (weight_k)`.</p>
                     <div class="code-block">
                        <button class="copy-code-btn" onclick="copyCode(this)">Copy</button>
                        <pre><code class="language-python"><span class="keyword">def</span> <span class="function">integrate_paths</span>(<span class="variable">list_of_paths</span>, <span class="variable">path_weights</span>):
    <span class="variable">stacked_paths</span> = torch.stack(<span class="variable">list_of_paths</span>) <span class="comment"># (num_paths, num_frames, latent_dim)</span>
    <span class="variable">weights_reshaped</span> = <span class="variable">path_weights</span>.view(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>) <span class="comment"># For broadcasting</span>
    
    <span class="variable">integrated_path</span> = torch.sum(<span class="variable">stacked_paths</span> * <span class="variable">weights_reshaped</span>, dim=<span class="number">0</span>)
    <span class="keyword">return</span> <span class="variable">integrated_path</span></code></pre>
                    </div>
                    <div class="mt-6 p-4 bg-indigo-50 rounded-lg border border-indigo-200">
                        <h5 class="font-medium text-indigo-600 mb-2">Visualizing Integration:</h5>
                        <p class="text-xs text-stone-500 mb-2">Imagine many faint paths (light gray). The path integral (dark blue) is their weighted average, pulled stronger towards paths with higher weights (lower action).</p>
                        <canvas id="pathIntegrationCanvas" class="w-full h-48 bg-white rounded border border-indigo-300"></canvas>
                    </div>
                </div>
                <!-- Phase 3 Content -->
                <div id="phase3" class="tab-content hidden">
                     <h3 class="text-2xl font-semibold mb-3 text-stone-800">Phase 3: Control and Refinement</h3>
                    <p class="text-stone-600 mb-6 text-base leading-relaxed">This phase empowers the creator. By adjusting prompts, setting waypoints, and fine-tuning action function parameters (like `w_smooth`, `w_semantic`, and `temperature`), the user sculpts the video's creative direction. The system is designed for an iterative feedback loop.</p>
                    <p class="text-stone-600 mb-4 text-base leading-relaxed">Key control levers include:</p>
                    <ul class="list-disc list-inside space-y-2 text-stone-600 mb-4">
                        <li><strong>Start/End Prompts/Images:</strong> Define the video's boundaries.</li>
                        <li><strong>Intermediate Prompts:</strong> Guide the narrative through specific concepts.</li>
                        <li><strong>Action Function Weights (w<sub>i</sub>):</strong> Prioritize smoothness, semantic adherence, novelty, etc. (as seen in Phase 1).</li>
                        <li><strong>Temperature (T):</strong> Controls the "strictness" of path selection in Phase 2. Low T = sharp selection of best paths; High T = broader averaging.</li>
                    </ul>
                    <p class="text-stone-600 text-base leading-relaxed">The goal is a collaborative process where human intuition and algorithmic exploration work together to achieve the desired visual output. The code examples in previous phases show how these parameters directly influence calculations.</p>
                </div>
            </div>
        </section>

        <section id="workflow" class="py-16">
            <div class="text-center mb-16">
                <h2 class="text-3xl font-bold tracking-tight text-stone-900 flex items-center justify-center"><span class="section-icon">üîÑ</span>Interactive Workflow</h2>
                <p class="mt-4 max-w-2xl mx-auto text-lg text-stone-600">This diagram visualizes the end-to-end journey. Click any step to unveil a detailed explanation and a technical snapshot of its role.</p>
            </div>
            <div class="w-full overflow-x-auto pb-6">
                <div class="flex flex-col md:flex-row items-stretch md:items-center justify-center space-y-4 md:space-y-0 md:space-x-2 min-w-[900px] px-4">
                    <div class="workflow-node bg-indigo-200 text-indigo-800 font-semibold p-4 rounded-xl shadow-md text-center flex-1 md:flex-initial min-h-[60px] flex items-center justify-center" data-step="1">1. User Input</div>
                    <div class="workflow-arrow w-full md:w-16 h-8 md:h-auto self-center"></div>
                    <div class="workflow-node bg-indigo-200 text-indigo-800 font-semibold p-4 rounded-xl shadow-md text-center flex-1 md:flex-initial min-h-[60px] flex items-center justify-center" data-step="2">2. Path Sampling</div>
                    <div class="workflow-arrow w-full md:w-16 h-8 md:h-auto self-center"></div>
                    <div class="workflow-node bg-indigo-200 text-indigo-800 font-semibold p-4 rounded-xl shadow-md text-center flex-1 md:flex-initial min-h-[60px] flex items-center justify-center" data-step="3">3. Path Integration</div>
                    <div class="workflow-arrow w-full md:w-16 h-8 md:h-auto self-center"></div>
                    <div class="workflow-node bg-indigo-200 text-indigo-800 font-semibold p-4 rounded-xl shadow-md text-center flex-1 md:flex-initial min-h-[60px] flex items-center justify-center" data-step="4">4. Frame Generation</div>
                    <div class="workflow-arrow w-full md:w-16 h-8 md:h-auto self-center"></div>
                    <div class="workflow-node bg-green-200 text-green-800 font-semibold p-4 rounded-xl shadow-md text-center flex-1 md:flex-initial min-h-[60px] flex items-center justify-center" data-step="5">5. Output Video</div>
                </div>
            </div>
        </section>
        
        <section id="challenges" class="py-16">
           <div class="text-center mb-16">
                <h2 class="text-3xl font-bold tracking-tight text-stone-900 flex items-center justify-center"><span class="section-icon">üéØ</span>Challenges & The Road Ahead</h2>
                <p class="mt-4 max-w-2xl mx-auto text-lg text-stone-600">This ambitious voyage presents fascinating problems to solve and exciting frontiers to explore. Here's a glimpse of the key hurdles and future horizons.</p>
            </div>
            <div class="grid md:grid-cols-2 gap-10">
                <div>
                    <h3 class="text-2xl font-semibold mb-6 text-center text-stone-800">Key Challenges</h3>
                    <div class="space-y-5">
                        <div class="challenge-future-card bg-white p-5 rounded-lg shadow-lg border-l-4 border-rose-500">
                            <h4 class="font-semibold text-rose-600 text-lg mb-1 flex items-center"><span class="mr-2">üèãÔ∏è</span>Computational Cost</h4>
                            <p class="text-sm text-stone-600 leading-relaxed">Sampling and evaluating thousands, potentially millions, of high-dimensional paths is an immense computational undertaking, demanding significant GPU resources and optimized algorithms.</p>
                        </div>
                        <div class="challenge-future-card bg-white p-5 rounded-lg shadow-lg border-l-4 border-rose-500">
                            <h4 class="font-semibold text-rose-600 text-lg mb-1 flex items-center"><span class="mr-2">üé®</span>Defining "Optimal" Action</h4>
                            <p class="text-sm text-stone-600 leading-relaxed">The "action" function is inherently subjective and application-dependent. Striking the perfect balance between creative exploration, visual coherence, and narrative intent is a profound research question.</p>
                        </div>
                         <div class="challenge-future-card bg-white p-5 rounded-lg shadow-lg border-l-4 border-rose-500">
                            <h4 class="font-semibold text-rose-600 text-lg mb-1 flex items-center"><span class="mr-2">üñºÔ∏è</span>Ensuring Visual Quality</h4>
                            <p class="text-sm text-stone-600 leading-relaxed">Averaging a multitude of paths, if not meticulously guided by a robust action function, could inadvertently lead to visually indistinct, blurry, or semantically nonsensical intermediate states.</p>
                        </div>
                    </div>
                </div>
                <div>
                    <h3 class="text-2xl font-semibold mb-6 text-center text-stone-800">Future Directions</h3>
                     <div class="space-y-5">
                        <div class="challenge-future-card bg-white p-5 rounded-lg shadow-lg border-l-4 border-emerald-500">
                            <h4 class="font-semibold text-emerald-600 text-lg mb-1 flex items-center"><span class="mr-2">üïπÔ∏è</span>Interactive Path Steering</h4>
                            <p class="text-sm text-stone-600 leading-relaxed">Develop intuitive, real-time interfaces that empower users to dynamically "steer" or influence the path integration process, akin to conducting an orchestra of possibilities.</p>
                        </div>
                        <div class="challenge-future-card bg-white p-5 rounded-lg shadow-lg border-l-4 border-emerald-500">
                            <h4 class="font-semibold text-emerald-600 text-lg mb-1 flex items-center"><span class="mr-2">üß†</span>Learning the Action Function</h4>
                            <p class="text-sm text-stone-600 leading-relaxed">Employ machine learning techniques to train an adaptive action function. This model could learn from user ratings of generated videos, creating a personalized and evolving creative partner.</p>
                        </div>
                         <div class="challenge-future-card bg-white p-5 rounded-lg shadow-lg border-l-4 border-emerald-500">
                            <h4 class="font-semibold text-emerald-600 text-lg mb-1 flex items-center"><span class="mr-2">üîó</span>Conditional Integration</h4>
                            <p class="text-sm text-stone-600 leading-relaxed">Expand the framework to integrate paths conditioned on diverse external data streams, such as an audio track's rhythmic beat, a textual narrative's emotional arc, or even biometric feedback.</p>
                        </div>
                    </div>
                </div>
            </div>
        </section>
    </main>

    <div id="workflow-modal" class="modal-overlay fixed inset-0 bg-black/60 backdrop-blur-sm flex items-center justify-center p-4 z-[100] hidden opacity-0">
        <div class="modal-content bg-white rounded-xl shadow-2xl max-w-lg w-full p-6 md:p-8 transform scale-95 opacity-0">
            <div class="flex justify-between items-center mb-4">
                <h3 id="modal-title" class="text-xl font-semibold text-indigo-700"></h3>
                <button id="modal-close" class="text-stone-400 hover:text-indigo-600 text-2xl leading-none">&times;</button>
            </div>
            <p id="modal-body" class="text-stone-600 leading-relaxed mb-4"></p>
            <div id="modal-tech-snapshot" class="mt-4 pt-4 border-t border-stone-200">
                <h4 class="text-sm font-semibold text-stone-500 mb-2">Technical Snapshot:</h4>
                <div id="modal-code-block" class="code-block text-xs"></div>
            </div>
        </div>
    </div>
    
    <footer class="text-center py-10 mt-16 border-t border-stone-200 bg-stone-50">
        <p class="text-stone-500 text-sm">Conceptual document by John | Interactive experience crafted by Gemini</p>
        <p class="text-xs text-stone-400 mt-1">Exploring the frontiers of generative art.</p>
    </footer>

<script>
document.addEventListener('DOMContentLoaded', () => {
    const workflowDetails = {
        1: { 
            title: 'Step 1: User Input', 
            body: 'The process begins with user-provided parameters: start/end prompts or images, video duration, quality settings, and weights for the action function. These inputs define the creative boundaries for the video generation.',
            code: `<span class="comment"># User defines:</span>
<span class="variable">start_prompt</span> = <span class="string">"Impressionist painting of a cat"</span>
<span class="variable">end_prompt</span> = <span class="string">"Cyberpunk cityscape with a cat"</span>
<span class="variable">num_frames</span> = <span class="number">100</span>
<span class="variable">action_weights</span> = { <span class="string">'smooth'</span>: <span class="number">1.0</span>, <span class="string">'semantic'</span>: <span class="number">0.5</span> }`
        },
        2: { 
            title: 'Step 2: Path Sampling Loop', 
            body: 'The system generates many candidate paths (sequences of latent vectors) between start/end points. Each path is a unique potential video evolution. Its "Action" is calculated and stored.',
            code: `<span class="keyword">for</span> i <span class="keyword">in</span> <span class="function">range</span>(<span class="variable">num_sample_paths</span>):
    <span class="variable">candidate_path</span> = <span class="function">generate_perturbed_path</span>(<span class="variable">base_path</span>)
    <span class="variable">path_action</span> = <span class="function">calculate_total_action</span>(<span class="variable">candidate_path</span>, ...)
    <span class="variable">sampled_paths</span>.append((<span class="variable">candidate_path</span>, <span class="variable">path_action</span>))`
        },
        3: { 
            title: 'Step 3: Path Integration', 
            body: 'For each video frame, the system calculates a weighted average of latent vectors from all sampled paths. Paths with better "action" scores contribute more heavily.',
            code: `<span class="variable">path_weights</span> = <span class="function">get_path_weights</span>(<span class="variable">sampled_paths</span>, <span class="variable">temperature</span>)
<span class="variable">final_latent_sequence</span> = <span class="function">integrate_paths</span>(
    [p[<span class="number">0</span>] <span class="keyword">for</span> p <span class="keyword">in</span> <span class="variable">sampled_paths</span>], <span class="comment"># just the paths</span>
    <span class="variable">path_weights</span>
)`
        },
        4: { 
            title: 'Step 4: Frame Generation', 
            body: 'The integrated latent vector for each frame is passed to the Stable Diffusion VAE decoder. This converts the abstract latent representation into a concrete pixel image, one frame at a time.',
            code: `<span class="keyword">for</span> latent_z <span class="keyword">in</span> <span class="variable">final_latent_sequence</span>:
    <span class="comment"># Reshape latent_z to match VAE input (e.g., 1, 4, H/8, W/8)</span>
    <span class="variable">image_frame</span> = <span class="variable">vae_decoder</span>.<span class="function">decode</span>(<span class="variable">latent_z</span>.unsqueeze(<span class="number">0</span>)).sample
    <span class="variable">video_frames</span>.append(<span class="variable">image_frame</span>)`
        },
        5: { 
            title: 'Step 5: Output Video', 
            body: 'All generated image frames are assembled in sequence into a final video file (e.g., MP4). The user can then review and optionally refine parameters for another iteration.',
            code: `<span class="function">assemble_video</span>(<span class="variable">video_frames</span>, <span class="variable">fps</span>=<span class="number">24</span>, <span class="variable">output_path</span>=<span class="string">'final_video.mp4'</span>)
<span class="comment"># User reviews, potentially adjusts inputs, and re-runs.</span>`
        },
    };

    const tabButtons = document.querySelectorAll('.tab-button');
    const tabContents = document.querySelectorAll('.tab-content');
    tabButtons.forEach(button => {
        button.addEventListener('click', () => {
            tabButtons.forEach(btn => btn.classList.remove('active'));
            button.classList.add('active');
            const tabId = button.getAttribute('data-tab');
            tabContents.forEach(content => {
                content.classList.toggle('hidden', content.id !== tabId);
            });
             if (tabId === 'phase2') { // Specific animation for phase 2
                if (activeConcept && activeConcept.id === 'pathIntegrationCanvas') { // Already active
                    cancelAnimationFrame(activeConcept.animationFrame);
                }
                const canvasEl = document.getElementById('pathIntegrationCanvas');
                if (canvasEl) {
                     activeConcept = { 
                        ctx: canvasEl.getContext('2d'), 
                        id: 'pathIntegrationCanvas', 
                        animFunc: animatePathIntegrationCanvas,
                        card: null // Not a concept card
                    };
                    resizeCanvas(activeConcept.ctx.canvas);
                    activeConcept.animFunc();
                }
            } else { // Stop phase 2 animation if switching away
                if (activeConcept && activeConcept.id === 'pathIntegrationCanvas') {
                    cancelAnimationFrame(activeConcept.animationFrame);
                    const ctxToClear = document.getElementById('pathIntegrationCanvas')?.getContext('2d');
                    if(ctxToClear) ctxToClear.clearRect(0,0,ctxToClear.canvas.width, ctxToClear.canvas.height);
                    activeConcept = null; 
                }
            }
        });
    });

    const actionSliders = {
        smoothness: document.getElementById('smoothness'),
        semantic: document.getElementById('semantic'),
        constraint: document.getElementById('constraint'),
        novelty: document.getElementById('novelty'),
    };
    const actionExplainer = document.getElementById('action-explainer');
    const actionCodeSnippet = document.getElementById('action_code_snippet');
    const ctxAction = document.getElementById('actionChart').getContext('2d');
    const actionChart = new Chart(ctxAction, {
        type: 'bar',
        data: {
            labels: ['Smoothness', 'Semantics', 'Constraints', 'Novelty'],
            datasets: [{
                label: 'Weighting', data: [70, 85, 50, 40],
                backgroundColor: ['rgba(79, 70, 229, 0.7)','rgba(129, 140, 248, 0.7)','rgba(167, 139, 250, 0.7)','rgba(196, 181, 253, 0.7)'],
                borderColor: ['#4f46e5','#818cf8','#a78bfa','#c4b5fd'],
                borderWidth: 2, borderRadius: 4, borderSkipped: false,
            }]
        },
        options: {
            responsive: true, maintainAspectRatio: false, indexAxis: 'y',
            scales: { x: { beginAtZero: true, max: 100, grid: { display: false }, ticks: { font: { size: 10 } } }, y: { grid: { display: false }, ticks: { font: { size: 12 } } } },
            plugins: { legend: { display: false }, tooltip: { enabled: true, backgroundColor: '#292524', titleFont: { weight: 'bold' }, bodyFont: { size: 12 }, padding: 10, cornerRadius: 4, callbacks: { label: (ctx) => `Current Weight: ${ctx.raw}` } } },
            animation: { duration: 500, easing: 'easeInOutQuart' }
        }
    });

    function updateActionFramework() {
        const ws = parseInt(actionSliders.smoothness.value);
        const wsem = parseInt(actionSliders.semantic.value);
        const wc = parseInt(actionSliders.constraint.value); // Assuming you might use this in the formula
        const wn = parseInt(actionSliders.novelty.value);   // Assuming you might use this

        actionChart.data.datasets[0].data = [ws, wsem, wc, wn];
        actionChart.update();

        const values = [ws, wsem, wc, wn];
        const labels = actionChart.data.labels;
        const maxVal = Math.max(...values);
        const dominantFactors = values.map((val, index) => val === maxVal ? labels[index] : null).filter(Boolean);
        let explainerText = 'Current focus: ';
        explainerText += dominantFactors.length > 1 ? dominantFactors.slice(0, -1).join(', ') + ' & ' + dominantFactors.slice(-1) : dominantFactors[0];
        actionExplainer.innerHTML = `üí° ${explainerText}, guiding path generation.`;

        actionCodeSnippet.innerHTML = `<span class="keyword">def</span> <span class="function">calculate_total_action</span>(<span class="variable">path</span>, <span class="variable">w_smooth</span>, <span class="variable">w_semantic</span>, ...):
    <span class="variable">s_smooth</span> = <span class="function">calculate_smoothness_action</span>(<span class="variable">path</span>)
    <span class="variable">s_semantic</span> = <span class="function">calculate_semantic_action</span>(<span class="variable">path</span>, ...)
    <span class="comment"># Other terms for constraints, novelty etc. would be here</span>
    <span class="variable">total_action</span> = (<span class="number">${(ws/100).toFixed(2)}</span> * <span class="variable">s_smooth</span>) 
                   - (<span class="number">${(wsem/100).toFixed(2)}</span> * <span class="variable">s_semantic</span>) 
                   <span class="comment"># + w_constraint * s_constraint ...</span>
    <span class="keyword">return</span> <span class="variable">total_action</span>`;
    }

    Object.values(actionSliders).forEach(slider => slider.addEventListener('input', updateActionFramework));
    updateActionFramework();

    const modal = document.getElementById('workflow-modal');
    const modalClose = document.getElementById('modal-close');
    const modalTitle = document.getElementById('modal-title');
    const modalBody = document.getElementById('modal-body');
    const modalCodeBlock = document.getElementById('modal-code-block');
    const workflowNodes = document.querySelectorAll('.workflow-node');
    let activeWfNode = null;
    
    workflowNodes.forEach(node => {
        node.addEventListener('click', () => {
            const step = node.dataset.step;
            modalTitle.textContent = workflowDetails[step].title;
            modalBody.textContent = workflowDetails[step].body;
            modalCodeBlock.innerHTML = workflowDetails[step].code;
            modal.classList.remove('hidden');
            
            if(activeWfNode) activeWfNode.classList.remove('active-node');
            node.classList.add('active-node');
            activeWfNode = node;

            setTimeout(() => {
                modal.classList.remove('opacity-0');
                modal.querySelector('.modal-content').classList.remove('scale-95', 'opacity-0');
            }, 10);
        });
    });

    function closeModal() {
        modal.classList.add('opacity-0');
        modal.querySelector('.modal-content').classList.add('scale-95', 'opacity-0');
        if(activeWfNode) activeWfNode.classList.remove('active-node');
        activeWfNode = null;
        setTimeout(() => modal.classList.add('hidden'), 300);
    }
    
    modalClose.addEventListener('click', closeModal);
    modal.addEventListener('click', (e) => { if (e.target === modal) closeModal(); });

    const conceptCanvases = {
        latent: { ctx: document.getElementById('canvas-latent').getContext('2d'), id: 1, animFunc: animateLatentSpace, card: document.getElementById('concept-card-1') },
        path: { ctx: document.getElementById('canvas-path').getContext('2d'), id: 2, animFunc: animatePathConceptCanvas, card: document.getElementById('concept-card-2') },
        video: { ctx: document.getElementById('canvas-video').getContext('2d'), id: 3, animFunc: animateVideoSynthesis, card: document.getElementById('concept-card-3') },
    };
    let activeConcept = null; 
    let globalFrame = 0;

    function resizeCanvas(canvas) {
        if (!canvas) return;
        const parent = canvas.parentElement;
        if (!parent) return;
        const rect = parent.getBoundingClientRect();
        canvas.width = rect.width;
        canvas.height = rect.height;
    }

    function resizeAllCanvases() {
        Object.values(conceptCanvases).forEach(c => {
            if (c.ctx && c.ctx.canvas) resizeCanvas(c.ctx.canvas);
        });
        const pathIntegCanvas = document.getElementById('pathIntegrationCanvas');
        if (pathIntegCanvas) resizeCanvas(pathIntegCanvas);

        if (activeConcept) { // Redraw active animation
            cancelAnimationFrame(activeConcept.animationFrame);
            if (activeConcept.animFunc) activeConcept.animFunc();
        } else { // Redraw static placeholders for concept cards if none active
             Object.values(conceptCanvases).forEach(c => {
                if (c.ctx && c.ctx.canvas && (!activeConcept || activeConcept.id !== c.id)) {
                     drawStaticPlaceholder(c.ctx, c.id);
                }
            });
        }
    }
    
    function drawStaticPlaceholder(ctx, id) {
        if (!ctx || !ctx.canvas) return;
        const w = ctx.canvas.width;
        const h = ctx.canvas.height;
        ctx.clearRect(0,0,w,h);
        ctx.fillStyle = '#A8A29E'; 
        ctx.textAlign = 'center';
        ctx.font = 'bold 13px Inter';
        
        if (id === 1) { 
            ctx.beginPath(); ctx.ellipse(w/2, h/2, w*0.35, h*0.25, 0, 0, 2*Math.PI);
            ctx.strokeStyle = '#A8A29E'; ctx.lineWidth = 2; ctx.stroke();
            ctx.fillText('Latent Space', w/2, h/2 + 5);
        } else if (id === 2) { 
            ctx.beginPath(); ctx.moveTo(w*0.15, h*0.5);
            ctx.bezierCurveTo(w*0.3, h*0.2, w*0.7, h*0.8, w*0.85, h*0.5);
            ctx.strokeStyle = '#A8A29E'; ctx.lineWidth = 2; ctx.stroke();
            ctx.fillText('Path Concept', w/2, h/2+5);
        } else if (id === 3) { 
            for(let i=0; i<3; i++) { ctx.strokeRect(w/2 - 45 + i*30, h/2 - 20, 25, 40); }
            ctx.fillText('Video Frames', w/2, h/2+5);
        }
    }

    Object.values(conceptCanvases).forEach(c => {
        if (!c.card) return;
        c.card.addEventListener('click', () => {
            if (activeConcept && activeConcept.card) {
                activeConcept.card.classList.remove('active-concept');
                cancelAnimationFrame(activeConcept.animationFrame);
                if (activeConcept.id !== 'pathIntegrationCanvas') drawStaticPlaceholder(activeConcept.ctx, activeConcept.id);
            }
            
            // Stop path integration animation if it's running
            if (activeConcept && activeConcept.id === 'pathIntegrationCanvas') {
                 cancelAnimationFrame(activeConcept.animationFrame);
                 const ctxToClear = document.getElementById('pathIntegrationCanvas')?.getContext('2d');
                 if(ctxToClear) ctxToClear.clearRect(0,0,ctxToClear.canvas.width, ctxToClear.canvas.height);
            }

            activeConcept = c;
            c.card.classList.add('active-concept');
            globalFrame = 0; 
            resizeCanvas(c.ctx.canvas); // Ensure canvas is sized before drawing
            c.animFunc();
        });
    });
    
    window.addEventListener('resize', resizeAllCanvases);
    resizeAllCanvases(); 

    function animateLatentSpace() {
        globalFrame++;
        if (!activeConcept || activeConcept.id !== 1 || !activeConcept.ctx) return;
        const ctx = activeConcept.ctx;
        const w = ctx.canvas.width; const h = ctx.canvas.height;
        ctx.clearRect(0, 0, w, h);
        ctx.fillStyle = 'rgba(79, 70, 229, 0.05)'; 
        ctx.beginPath(); ctx.ellipse(w/2, h/2, w*0.4, h*0.3, Math.sin(globalFrame*0.005)*0.1, 0, 2*Math.PI); ctx.fill();
        const x = w/2 + Math.cos(globalFrame * 0.025) * w * 0.3;
        const y = h/2 + Math.sin(globalFrame * 0.03) * h * 0.2;
        const size = 6 + Math.sin(globalFrame * 0.05) * 2;
        ctx.fillStyle = '#4f46e5'; ctx.beginPath(); ctx.arc(x, y, size, 0, 2 * Math.PI);
        ctx.shadowColor = 'rgba(79, 70, 229, 0.5)'; ctx.shadowBlur = 8; ctx.fill(); ctx.shadowBlur = 0;
        activeConcept.animationFrame = requestAnimationFrame(animateLatentSpace);
    }

    function animatePathConceptCanvas() {
        globalFrame++;
        if (!activeConcept || activeConcept.id !== 2 || !activeConcept.ctx) return;
        const ctx = activeConcept.ctx;
        const w = ctx.canvas.width; const h = ctx.canvas.height;
        ctx.clearRect(0, 0, w, h);
        const start = { x: w * 0.1, y: h * 0.5 }; const end = { x: w * 0.9, y: h * 0.5 };
        ctx.lineWidth = 1.5;
        for (let i = 0; i < 5; i++) {
            ctx.beginPath(); ctx.moveTo(start.x, start.y);
            const sway = Math.sin(globalFrame * 0.01 + i * 0.5) * (h * 0.15);
            const cp1x = w * 0.3 + Math.sin(globalFrame * 0.015 + i) * 15;
            const cp1y = h * 0.5 - h*0.25 + sway * (i%2 === 0 ? 1 : -1) * (0.5 + i*0.1);
            const cp2x = w * 0.7 + Math.cos(globalFrame * 0.015 + i) * 15;
            const cp2y = h * 0.5 + h*0.25 - sway * (i%2 === 0 ? 1 : -1) * (0.5 + i*0.1);
            ctx.strokeStyle = `rgba(167, 139, 250, ${0.2 + i*0.08})`;
            ctx.bezierCurveTo(cp1x, cp1y, cp2x, cp2y, end.x, end.y); ctx.stroke();
        }
        ctx.strokeStyle = '#4f46e5'; ctx.lineWidth = 3; ctx.beginPath(); ctx.moveTo(start.x, start.y);
        const mainSway = Math.sin(globalFrame * 0.02) * (h*0.05);
        ctx.bezierCurveTo(w * 0.35, h * 0.5 - h*0.1 + mainSway, w * 0.65, h * 0.5 + h*0.1 - mainSway, end.x, end.y);
        ctx.shadowColor = 'rgba(79, 70, 229, 0.5)'; ctx.shadowBlur = 10; ctx.stroke(); ctx.shadowBlur = 0;
        ctx.fillStyle = '#4f46e5'; [start, end].forEach(p => { ctx.beginPath(); ctx.arc(p.x, p.y, 6, 0, 2 * Math.PI); ctx.fill(); });
        activeConcept.animationFrame = requestAnimationFrame(animatePathConceptCanvas);
    }
    
    let videoConceptFrames = []; const maxVideoConceptFrames = 8;
    function animateVideoSynthesis() {
        globalFrame++;
        if (!activeConcept || activeConcept.id !== 3 || !activeConcept.ctx) return;
        const ctx = activeConcept.ctx;
        const w = ctx.canvas.width; const h = ctx.canvas.height;
        ctx.clearRect(0, 0, w, h);
        const frameWidth = Math.min(40, w / (maxVideoConceptFrames + 3)); const frameHeight = frameWidth * 1.5;
        if (globalFrame % 20 === 0) {
            if (videoConceptFrames.length >= maxVideoConceptFrames) videoConceptFrames.shift();
            videoConceptFrames.push({ hue: 220 + Math.random() * 60, alpha: 0, yOffset: (Math.random() - 0.5) * (h*0.1) });
        }
        videoConceptFrames.forEach((f, i) => {
            if (f.alpha < 1) f.alpha += 0.05;
            const x = (w / (videoConceptFrames.length + 1)) * (i + 1);
            ctx.fillStyle = `hsla(${f.hue}, 70%, 60%, ${f.alpha})`; ctx.strokeStyle = `hsla(${f.hue}, 70%, 40%, ${f.alpha})`;
            ctx.lineWidth = 2; ctx.beginPath(); ctx.roundRect(x - frameWidth/2, h/2 - frameHeight/2 + f.yOffset, frameWidth, frameHeight, 4);
            ctx.fill(); ctx.stroke();
        });
        activeConcept.animationFrame = requestAnimationFrame(animateVideoSynthesis);
    }

    let pathIntegrationAnimFrame;
    function animatePathIntegrationCanvas() {
        if (!activeConcept || activeConcept.id !== 'pathIntegrationCanvas' || !activeConcept.ctx) return;
        const ctx = activeConcept.ctx;
        const w = ctx.canvas.width; const h = ctx.canvas.height;
        globalFrame++;
        ctx.clearRect(0,0,w,h);

        const start = {x: w * 0.1, y: h * 0.5};
        const end = {x: w * 0.9, y: h * 0.5};

        const numPaths = 7;
        const pathsData = [];

        for(let i=0; i<numPaths; i++) {
            const weight = Math.pow(Math.sin( (i / numPaths) * Math.PI + globalFrame * 0.01), 2); // Weight pulsates
            const amplitude = (h * 0.3) * (1 - weight * 0.7); // Higher weight = less deviation for main path
            const cp1y = start.y - amplitude * Math.sin( (i / numPaths) * Math.PI * 2 + globalFrame * 0.02);
            const cp2y = end.y + amplitude * Math.cos( (i / numPaths) * Math.PI * 2 + globalFrame * 0.02);
            pathsData.push({cp1y, cp2y, weight});
        }
        
        // Draw faint paths
        ctx.lineWidth = 1;
        pathsData.forEach(p => {
            ctx.strokeStyle = `rgba(167, 139, 250, ${0.1 + p.weight * 0.3})`; // Fainter, slightly influenced by weight
            ctx.beginPath();
            ctx.moveTo(start.x, start.y);
            ctx.bezierCurveTo(w * 0.3, p.cp1y, w * 0.7, p.cp2y, end.x, end.y);
            ctx.stroke();
        });

        // Calculate weighted average control points for the main "integrated" path
        let weightedCp1ySum = 0;
        let weightedCp2ySum = 0;
        let totalWeightSum = 0;
        pathsData.forEach(p => {
            weightedCp1ySum += p.cp1y * p.weight;
            weightedCp2ySum += p.cp2y * p.weight;
            totalWeightSum += p.weight;
        });

        const avgCp1y = totalWeightSum > 0 ? weightedCp1ySum / totalWeightSum : h * 0.5;
        const avgCp2y = totalWeightSum > 0 ? weightedCp2ySum / totalWeightSum : h * 0.5;

        // Draw main integrated path
        ctx.lineWidth = 3 + Math.sin(globalFrame * 0.03) * 1.5; // Pulsating width
        ctx.strokeStyle = '#4f46e5';
        ctx.beginPath();
        ctx.moveTo(start.x, start.y);
        ctx.bezierCurveTo(w * 0.3, avgCp1y, w * 0.7, avgCp2y, end.x, end.y);
        ctx.shadowColor = 'rgba(79, 70, 229, 0.5)'; ctx.shadowBlur = 10; ctx.stroke(); ctx.shadowBlur = 0;

        ctx.fillStyle = '#4f46e5';
        [start,end].forEach(p => { ctx.beginPath(); ctx.arc(p.x, p.y, 5, 0, 2 * Math.PI); ctx.fill(); });
        
        activeConcept.animationFrame = requestAnimationFrame(animatePathIntegrationCanvas);
    }
});

function copyCode(button) {
    const codeElement = button.nextElementSibling.querySelector('code');
    const textToCopy = codeElement.innerText;
    const tempTextArea = document.createElement('textarea');
    tempTextArea.value = textToCopy;
    document.body.appendChild(tempTextArea);
    tempTextArea.select();
    document.execCommand('copy');
    document.body.removeChild(tempTextArea);
    button.innerText = 'Copied!';
    setTimeout(() => { button.innerText = 'Copy'; }, 2000);
}
</script>

</body>
</html>
